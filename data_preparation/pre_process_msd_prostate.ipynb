{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n",
      "torch.Size([1, 96, 96, 64]) torch.Size([1, 96, 96, 64])\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import torch\n",
    "from monai.transforms import (\n",
    "    SpatialCropd,\n",
    "    Compose,\n",
    "    RandShiftIntensityd\n",
    ")\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monai.transforms import Resized, Compose, LoadImaged, Spacingd, EnsureChannelFirstd, Orientationd, ScaleIntensityRanged, CropForegroundd, SpatialCropd, CenterSpatialCropd, SpatialPadd\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "\n",
    "def convert_label(input_label):\n",
    "    input_label_5 = (input_label == 2).float()\n",
    "    input_label_4 = (input_label == 1).float()\n",
    "    return input_label_5 + input_label_4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Load_File(object):\n",
    "    \"\"\"load the file dir dict and convert to actualy file dir\"\"\"\n",
    "    \n",
    "    def load_file(self, input_dict):\n",
    "    \n",
    "        data_dict = {\n",
    "            'image': torch.from_numpy(nib.load(input_dict['image']).get_fdata())[:, :, :, 0].unsqueeze(0), \n",
    "            'label': convert_label(torch.from_numpy(nib.load(input_dict['label']).get_fdata()).unsqueeze(0))\n",
    "        }\n",
    "        return data_dict\n",
    "\n",
    "    def __call__(self, input_dict):\n",
    "        return self.load_file(input_dict)\n",
    "\n",
    "\n",
    "data_reader = Compose(\n",
    "    [\n",
    "        Load_File(),\n",
    "        # EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        # Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        # Spacingd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     pixdim=(2.0, 2.0, 3.0),\n",
    "        #     mode=(\"bilinear\", \"nearest\"),\n",
    "        # ),\n",
    "        # ScaleIntensityRanged(\n",
    "        #     keys=[\"image\"],\n",
    "        #     a_min=-125,\n",
    "        #     a_max=125,\n",
    "        #     b_min=0.0,\n",
    "        #     b_max=1.0,\n",
    "        #     clip=True,\n",
    "        # ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Resized(keys=[\"image\", \"label\"], spatial_size=(128, 128, 64)),\n",
    "        \n",
    "        CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=(96, 96, 64)),\n",
    "        # SpatialCropd(keys=[\"image\", \"label\"], roi_center=(50, 74, 80) , roi_size=(96, 96, 96)),\n",
    "        # SpatialPadd(keys=['image', 'label'], spatial_size=(96, 96, 96))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_h5(img_dir, label_dir, des_dir):\n",
    "    for img_name in os.listdir(img_dir):\n",
    "        # make sure all data are CT data\n",
    "    \n",
    "        image_index = img_name[9:11]\n",
    "        img_path = os.path.join(img_dir, 'prostate_' + image_index + '.nii.gz')\n",
    "        # print(img_dir)\n",
    "        label_path = os.path.join(label_dir, 'prostate_' + image_index + '.nii.gz')\n",
    "\n",
    "        dir_dict = {\n",
    "            'image' : img_path,\n",
    "            'label' : label_path\n",
    "        }\n",
    "        \n",
    "        loaded_dict = data_reader(dir_dict)\n",
    "        print(loaded_dict['image'].shape, loaded_dict['label'].shape)\n",
    "        with h5py.File(os.path.join(des_dir, image_index + '.h5'), 'w') as hf:\n",
    "            hf.create_dataset('image', data=loaded_dict['image'])\n",
    "            hf.create_dataset('label', data=(loaded_dict['label'] > 0.5).float())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# file_dir = {'image': '/home/xiangcen/xiaoyao/prostate_training/Task05_Prostate/imagesTr/prostate_00.nii.gz',\n",
    "#             'label': '/home/xiangcen/xiaoyao/prostate_training/Task05_Prostate/labelsTr/prostate_00.nii.gz'}\n",
    "# print(file_dir['label'])\n",
    "\n",
    "# batch = data_reader(file_dir)\n",
    "# img, label = batch['image'], batch['label']\n",
    "# print(img.shape)\n",
    "# plt.imshow(label[0, :, :, 32])\n",
    "\n",
    "convert_h5('/home/xiangcen/xiaoyao/prostate_training/Task05_Prostate/imagesTr', '/home/xiangcen/xiaoyao/prostate_training/Task05_Prostate/labelsTr', '/home/xiangcen/xiaoyao/prostate_training/data_prostate_msd_h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "from monai.transforms import (\n",
    "    SpatialCropd,\n",
    "    Compose,\n",
    "    RandShiftIntensityd\n",
    ")\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monai.transforms import Resized, Compose, LoadImaged, Spacingd, EnsureChannelFirstd, Orientationd, ScaleIntensityRanged, CropForegroundd, SpatialCropd, CenterSpatialCropd, SpatialPadd\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "\n",
    "# def load_file(input_dict):\n",
    "    \n",
    "#     data_dict = {\n",
    "#         'image': torch.tensor(nib.load(input_dict['image']).get_fdata()), \n",
    "#         'label': convert_label(torch.tensor(nib.load(input_dict['label']).get_fdata()))\n",
    "#     }\n",
    "#     return data_dict\n",
    "\n",
    "\n",
    "\n",
    "class Load_File(object):\n",
    "    \"\"\"load the file dir dict and convert to actualy file dir\"\"\"\n",
    "    \n",
    "    def load_file(self, input_dict):\n",
    "    \n",
    "        data_dict = {\n",
    "            'image': torch.tensor(nib.load(input_dict['image']).get_fdata()).unsqueeze(0), \n",
    "            'label': convert_label(torch.tensor(nib.load(input_dict['label']).get_fdata())).unsqueeze(0)\n",
    "        }\n",
    "        return data_dict\n",
    "\n",
    "    def __call__(self, input_dict):\n",
    "        return self.load_file(input_dict)\n",
    "\n",
    "\n",
    "data_reader = Compose(\n",
    "    [\n",
    "        Load_File(),\n",
    "        # EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        # Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        # Spacingd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     pixdim=(2.0, 2.0, 3.0),\n",
    "        #     mode=(\"bilinear\", \"nearest\"),\n",
    "        # ),\n",
    "        # ScaleIntensityRanged(\n",
    "        #     keys=[\"image\"],\n",
    "        #     a_min=-125,\n",
    "        #     a_max=125,\n",
    "        #     b_min=0.0,\n",
    "        #     b_max=1.0,\n",
    "        #     clip=True,\n",
    "        # ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Resized(keys=[\"image\", \"label\"], spatial_size=(128, 128, 64)),\n",
    "        \n",
    "        CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=(96, 96, 64)),\n",
    "        # SpatialCropd(keys=[\"image\", \"label\"], roi_center=(50, 74, 80) , roi_size=(96, 96, 96)),\n",
    "        # SpatialPadd(keys=['image', 'label'], spatial_size=(96, 96, 96))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def convert_label(input_label):\n",
    "    input_label_5 = (input_label == 5).float()\n",
    "    input_label_4 = (input_label == 4).float()\n",
    "    return input_label_5 + input_label_4\n",
    "\n",
    "\n",
    "def convert_h5(dir, des_dir):\n",
    "    for img_name in os.listdir(dir):\n",
    "        # make sure all data are CT data\n",
    "        if img_name.endswith('img.nii'):\n",
    "            image_index = img_name[:6]\n",
    "            img_dir = os.path.join(dir, image_index + '_img.nii')\n",
    "            label_dir = os.path.join(dir, image_index + '_mask.nii')\n",
    "\n",
    "            dir_dict = {\n",
    "                'image' : img_dir,\n",
    "                'label' : label_dir\n",
    "            }\n",
    "            \n",
    "            print(dir_dict)\n",
    "            \n",
    "            loaded_dict = data_reader(dir_dict)\n",
    "            print(loaded_dict['image'].shape)\n",
    "            with h5py.File(os.path.join(des_dir, image_index + '.h5'), 'w') as hf:\n",
    "                hf.create_dataset('image', data=loaded_dict['image'])\n",
    "                hf.create_dataset('label', data=(loaded_dict['label'] > 0.5).float())\n",
    "\n",
    "\n",
    "\n",
    "convert_h5('/home/xiangcen/xiaoyao/data_prostate', '/home/xiangcen/xiaoyao/prostate_training/data_prostate_h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
